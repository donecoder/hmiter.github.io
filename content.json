{"pages":[{"title":"黄敏","text":"生于89年，男，湖南人，毕业于吉首大学，小小本科生。现就职于智慧眼，从事半管理半开发工作。 主要从事Java开发，了解C、PHP、NodeJS，写过shell和python脚本。独立开发过微信、安卓应用，擅长后端开发，小至SSH，大到分布式，也玩过大数据处理。技术涉略比较杂。也算一个小小全栈吧。在管理方面只能说是马马虎虎吧！负责开发过几个项目，成功上线6、7个地方。 技术前端：HTML、CSS、JavaScript、Ajax、JQuery、EasyUI、bootstrap后端：Java、JVM、JavaIO、JavaThread、JNI、Struts2、Spring MVC、Spring、Mybatis、FreeMarker、Quartz、Dubbo、HSF(DEAS)、ActiveMQ、Mina、Lucence、WebService、WebSocket、Spring boot、Spring Cloud数据库：Oracle、MySQL和Mongodb缓存：Ehcache、MenCached、Redis中间件：Jetty、Tomcat、JBoss、Weblogic、Apache、Ngnix等。构建：ANT、Maven、Gradle、SVN、Git运维：Linux、shell，VMware开发工具：Eclipse、IDEA、PLSQL Developer、PowerDesigner、Rose大数据：Hadoop、HBase、Hive、Zookeeper其他：Android、第三方支付开发(微信、支付宝) 经历2012.07 – 2013.11 科盟软件有限公司2013.11 – 2017.05 北京智慧眼科技股份有限公司2017.05 – 2017.11 长沙东东科技有限公司2017.11 – 至今 湖南快乐阳光互动娱乐传媒有限公司(芒果TV) 箴言业精于勤荒于嬉","link":"/about/index.html"}],"posts":[{"title":"Android常用部署属性","text":"第一类：通用属性1234567891011android:id 设置IDandroid:layout_width 该组件的宽度,wrap_content|fill_parent|match_parentandroid:layout_height 该组件的高度，wrap_content|fill_parent|match_parentandroid:layout_gravity 该组件在父组件的对其方式，bottom|left|top|rightandroid:orientation 布局组件的内部子组件的排列方式，horizontal|verticalandroid:gravity 布局组件的内部子组件的对其方式,bottom|left|top|rightandroid:text 设置显示的文本内容，通过、string.xml文件引用android:textColor 设置字体颜色，通过colors.xml资源来引用android:textStyle 设置字体风格，normal(无效果)|bold(加粗)|italic(斜体)android:textSize 字体大小，单位一般是用sp！android:background 设置主键的背景图片 第二类:属性值为true或false12345678android:layout_centerHrizontal 水平居中android:layout_centerVertical 垂直居中android:layout_centerInparent 相对于父元素完全居中。android:layout_alignParentBottom 贴紧父元素的下边缘android:layout_alignParentLeft 贴紧父元素的左边缘android:layout_alignParentRight 贴紧父元素的右边缘android:layout_alignParentTop 贴紧父元素的上边缘android:layout_alignWithParentIfMissing 如果对应的兄弟元素找不到的话就以父元素做参照物 第三类：属性值必须为id的引用名“@id/id-name”12345678android:layout_below 在某元素的下方android:layout_above 在某元素的的上方android:layout_toLeftOf 在某元素的左边android:layout_toRightOf 在某元素的右边android:layout_alignTop 本元素的上边缘和某元素的的上边缘对齐android:layout_alignLeft 本元素的左边缘和某元素的的左边缘对齐android:layout_alignBottom 本元素的下边缘和某元素的的下边缘对齐android:layout_alignRight 本元素的右边缘和某元素的的右边缘对齐 第四类：属性值为具体的像素值，如30dip，40px12345678910android:layout_margin 离某元素上下左右的的距离android:layout_marginTop 离某元素上边缘的距离android:layout_marginRight 离某元素右边缘的距离android:layout_marginBottom 离某元素底边缘的距离android:layout_marginLeft 离某元素左边缘的距离android:padding 指该控件内部内容距离该控件上下左右边缘的边距android:paddingTop 指该控件内部内容距离该控件上边缘的边距android:paddingRight 指该控件内部内容距离该控件左边缘的边距android:paddingBottom 指该控件内部内容距离该控件下边缘的边距android:paddingLeft 指该控件内部内容距离该控件右边缘的边距","link":"/2017/03/18/Android常用部署属性/"},{"title":"Spring常用注解","text":"Java原生注解@Retention：注解说明,这种类型的注解会被保留到那个阶段1.RetentionPolicy.SOURCE —— 这种类型的Annotations只在源代码级别保留,编译时就会被忽略2.RetentionPolicy.CLASS —— 这种类型的Annotations编译时被保留,在class文件中存在,但JVM将会忽略3.RetentionPolicy.RUNTIME —— 这种类型的Annotations将被JVM保留,所以他们能在运行时被JVM或其他使用反射机制的代码所读取和使用. @Documented：作用是在生成javadoc文档的时候将该注解也写入到文档中。javadoc默认是不会将注解写到文档中的。 @Target:注解的使用的目标 @Target(ElementType.TYPE) //接口、类、枚举、注解 @Target(ElementType.FIELD) //字段、枚举的常量 @Target(ElementType.METHOD) //方法 @Target(ElementType.PARAMETER) //方法参数 @Target(ElementType.CONSTRUCTOR) //构造函数 @Target(ElementType.LOCAL_VARIABLE)//局部变量 @Target(ElementType.ANNOTATION_TYPE)//注解 @Target(ElementType.PACKAGE) ///包 @Inherited：它指明被注解的类的所有属性将会自动继承到它的子类中. #java EE规范@Resource：为目标bean指定协作者Bean@Inject：为目标bean指定协作者Bean@Named：为目标bean指定协作者Bean@Qualifier：@PostConstruct：在构造函数执行完成之后执行。@PreDestory：bean销毁之前的执行方法。 Spring注解@Component :标注一个普通的spring Bean类@Service :标注一个业务逻辑组件类。@Repository :标注一个DAO组件类。@Controller:标注一个控制器组件类。 @EnableWebMvc：开启MVC 方法级别@ResetController：组合注解，组合了@Controller和@RequestBody@RequestMapping：配置URI和方法之间的映射 @GetMapping @PostMapping @PutMapping@RequestHeader 注解，可以把Request请求header部分的值绑定到方法的参数上。如：@RequestHeader(“Accept-Encoding”) String encoding@CookieValue 可以把Request header中关于cookie的值绑定到方法的参数上。如：@CookieValue(“JSESSIONID”) String cookie @CrossOrigin:实现跨域访问。 参数@PathVariable：接受路径参数，如someUrl/{paramId}, 这时的paramId可通过 @Pathvariable注解绑定它传过来的值到方法的参数上。@RequestParam：A） 常用来处理简单类型的绑定，通过Request.getParameter() 获取的String可直接转换为简单类型的情况（ String–&gt; 简单类型的转换操作由ConversionService配置的转换器来完成）；因为使用request.getParameter()方式获取参数，所以可以处理get 方式中queryString的值，也可以处理post方式中 body data的值；B）用来处理Content-Type: 为 application/x-www-form-urlencoded编码的内容，提交方式GET、POST；C) 该注解有两个属性： value、required； value用来指定要传入值的id名称，required用来指示参数是否必须绑定；@RequestBody：该注解常用来处理Content-Type: 不是application/x-www-form-urlencoded编码的内容，例如application/json, application/xml等；它是通过使用HandlerAdapter 配置的HttpMessageConverters来解析post data body，然后绑定到相应的bean上的。因为配置有FormHttpMessageConverter，所以也可以用来处理 application/x-www-form-urlencoded的内容，处理完的结果放在一个MultiValueMap里，这种情况在某些特殊需求下使用 @InitBinder：用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求的参数到Model中。@ExceptionHandler：用于全局处理控制器里的异常。@ModelAttribute该注解有两个用法，一个是用于方法上，一个是用于参数上；用于方法上时： 通常用来在处理@RequestMapping之前，为请求绑定需要从后台查询的model；用于参数上时： 用来通过名称对应，把相应名称的值绑定到注解的参数bean上；要绑定的值来源于： @SessionAttribute:该注解用来绑定HttpSession中的attribute对象的值，便于在方法中的参数里使用。@RequestAttribute：可以被用于访问由过滤器或拦截器创建的、预先存在的请求属性 @ResponseBody：支持将返回值放在response的body体内 @Scope：注解也可以指定Bean实例的作用域。取值：Singleton(默认)|Prototype|Request|Session|GlobalSession@Autowired：为目标bean指定协作者Bean@Value：为属性注入值 @Aspect：声明一个切面@PointCut：定义拦截规则@After：标注一个之后建言@Before：标注一个之前建言@Around：标注一个运行时建言 @Transcational：事物@Cacheable：数据缓存 @EnableScheduling：开启计划任务@Scheduled：声明这是一个计划任务 @Import：since4.2。导入普通的java类,并将其声明成一个bean@Configuration：声明一个配置类@ComponentScan：制定Spring扫描包路径。@Bean 注解在方法上，声明当前方法的返回@Profile：可以注解在类或方法上。 在不同环境下使用不同配置提供支持。@Conditional：根据满足某一个特定条件创建一个特定的Bean。 Spring boot@SpringBootApplication ：会根据类路径中jar包自动进行相关配置。@EnableAutoConfiguration@ConfigurationProperties：加载一个properties文件。 @ConditionalOnBean:当容器里有指定的Bean的条件下@ConditionalOnClass:当类路径下有指定的类的条件下。@ConditionalOnExpression：基于SPEl表达式作为判断条件。@ConditionalOnJava：基于JVM版本作为判断条件。@ConditionalOnJndi:在JNDI存在的条件下查找指定的位置。@ConditionalOnMissingBean：当容器里没有指定Bean的条件下。@ConditionalOnMissingClass:当类路径下没有指定的类的条件下。@ConditionalOnWebApplication:当前项目是web项目的条件下。@ConditionalOnNotWebApplication:当前项目部是WEb项目的条件下。@ConditionalOnProperty:指定的属性是否有指定的值。@ConditionalOnResource：类路径是否有指定的值。@ConditionalOnSingleCandidate:当指定首选的Bean。","link":"/2017/04/20/Spring常用注解/"},{"title":"spring声明式事务配置","text":"上周要一个同事开发一个模块，他说事物死活不起作用。我看了一下，大致主要配置如下： 12345678910111213141516171819202122232425262728&lt;!-- 配置事务管理 --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"businessDataSource\" /&gt;&lt;/bean&gt;&lt;!-- 事务相关控制配置：例如配置事务的传播机制 --&gt;&lt;tx:advice id=\"fortressAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"get*\" propagation=\"SUPPORTS\" read-only=\"false\"/&gt; &lt;tx:method name=\"query*\" propagation=\"SUPPORTS\" read-only=\"false\" /&gt; &lt;tx:method name=\"count*\" propagation=\"SUPPORTS\" read-only=\"false\"/&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\" read-only=\"false\" /&gt; &lt;tx:method name=\"remove*\" propagation=\"REQUIRED\" read-only=\"false\" /&gt; &lt;tx:method name=\"modify*\" propagation=\"REQUIRED\" read-only=\"false\" /&gt; &lt;tx:method name=\"*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 事务控制切入点在service层|第一个 * —— 通配 任意返回值类型||第二个 * —— 通配包com.mindasoft.fortress.service下的任意class||第三个 * —— 通配包com.mindasoft.fortress.service下的任意class的任意方法||第四个 .. —— 通配 办法可以有0个或多个参数--&gt;&lt;aop:config&gt; &lt;aop:pointcut id=\"allFortressMethod\" expression=\"execution(* com.mindasoft.fortress.service.*.*(..))\" /&gt; &lt;aop:advisor advice-ref=\"fortressAdvice\" pointcut-ref=\"allFortressMethod\" /&gt;&lt;/aop:config&gt; 配置是这样没错，他的配置也问题，但是为什么会不起作用呢？Debug进行，发现根本就没有进入事物处理。为什么会这样？看配置web.xml1234567891011121314151617181920212223&lt;!-- Spring MVC 子Context配置 --&gt;&lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/config/servlet.web.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;2&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;!-- Spring root Context监听配置 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/config/**/*.bean.xml&lt;/param-value&gt;&lt;/context-param&gt; Spring和SpringMVC一起使用时，ContextLoaderListener会初始化一个Context，这个Context是RootContext，而DispatcherServlet也会初始化一个Context，简称WebContext。WebContext是RootContext的子集。当mvc有自己的bean时便不再去向父context要bean。 所以，在servlet.web.xml 和*.bean.xml 当中，各自的component-scan配置要指定相应位置，否则会导致bean混乱，从导致声明事务无效。如下：servlet.web.xml1&lt;context:component-scan base-package=\"com.mindasoft.*.controllers\" /&gt; *.bean.xml12&lt;context:component-scan base-package=\"com.mindasoft.*.dao\" /&gt;&lt;context:component-scan base-package=\"com.mindasoft.*.service\" /&gt; 当然你也可以使用DispatcherServlet加载全部的配置文件或者将AOP配置复制到servlet.web.xml中。 这个修改了之后还是不行？？看了下他的代码，他是自己写了一个Exception。然后断点跟踪源代码TransactionAspectSupport：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Handle a throwable, completing the transaction. * We may commit or roll back, depending on the configuration. * @param txInfo information about the current transaction * @param ex throwable encountered */protected void completeTransactionAfterThrowing(TransactionInfo txInfo, Throwable ex) { if (txInfo != null &amp;&amp; txInfo.hasTransaction()) { if (logger.isTraceEnabled()) { logger.trace(\"Completing transaction for [\" + txInfo.getJoinpointIdentification() + \"] after exception: \" + ex); } if (txInfo.transactionAttribute.rollbackOn(ex)) { try { txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus()); } catch (TransactionSystemException ex2) { logger.error(\"Application exception overridden by rollback exception\", ex); ex2.initApplicationException(ex); throw ex2; } catch (RuntimeException ex2) { logger.error(\"Application exception overridden by rollback exception\", ex); throw ex2; } catch (Error err) { logger.error(\"Application exception overridden by rollback error\", ex); throw err; } } else { // We don't roll back on this exception. // Will still roll back if TransactionStatus.isRollbackOnly() is true. try { txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); } catch (TransactionSystemException ex2) { logger.error(\"Application exception overridden by commit exception\", ex); ex2.initApplicationException(ex); throw ex2; } catch (RuntimeException ex2) { logger.error(\"Application exception overridden by commit exception\", ex); throw ex2; } catch (Error err) { logger.error(\"Application exception overridden by commit error\", ex); throw err; } } }} 上面的方法中有这么一段txInfo.transactionAttribute.rollbackOn(ex)，这里是判断是否需要执行回滚操作的，跟踪rollbackOn方法最后会执行到DefaultTransactionAttribute中的rollbackOn方法。12345678/** * The default behavior is as with EJB: rollback on unchecked exception. * Additionally attempt to rollback on Error. * &lt;p&gt;This is consistent with TransactionTemplate's default behavior. */public boolean rollbackOn(Throwable ex) { return (ex instanceof RuntimeException || ex instanceof Error);} 到这里，应该都清楚了。。。自己主动抛异常Exception是不对的。这里只捕获运行时异常RuntimeException 及Error，所以我们测试时不可以直接抛Exception，而应该换成RuntimeException 。当然。也可在xml中指定rollback-for。123456789101112&lt;!-- 事务相关控制配置：例如配置事务的传播机制 --&gt;&lt;tx:advice id=\"fortressAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"get*\" propagation=\"SUPPORTS\" read-only=\"false\"/&gt; &lt;tx:method name=\"query*\" propagation=\"SUPPORTS\" read-only=\"false\" /&gt; &lt;tx:method name=\"count*\" propagation=\"SUPPORTS\" read-only=\"false\"/&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\" read-only=\"false\" rollback-for=\"Exception\"/&gt; &lt;tx:method name=\"remove*\" propagation=\"REQUIRED\" read-only=\"false\" rollback-for=\"Exception\"/&gt; &lt;tx:method name=\"modify*\" propagation=\"REQUIRED\" read-only=\"false\" rollback-for=\"Exception\"/&gt; &lt;tx:method name=\"*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;","link":"/2017/03/19/spring声明式事务配置/"},{"title":"mysql安装成服务及自启动","text":"windows1、解压该压缩包，生成3分tomcat 分别命名为 tomcat1,tomcat2,tomcat3 2、进入tomcat1/conf/目录，修改server.xml的端口。 3、进入tomcat1/bin目录，修改 service.bat 4、修改SERVICE_NAME，如下123rem Set default Service nameset SERVICE_NAME=Tomcat7set DISPLAYNAME=Apache Tomcat 7.0 %SERVICE_NAME% 5、打开CMD命令控制台，进入tomcat1/bin目录，执行服务安装命令1service.bat install 注意：不要在环境变量设置CATALINA_HOME和CATALINA_HOME，否则无法生效！ 同理安装其他Tomcat。 PS：删除服务1service.bat uninstall linux简单自启动：1vim /etc/rc.local 在 exit 0 之前添加启动命令：1/home/tomcat/bin/startup.sh","link":"/2017/04/20/tomcat安装成服务及自启动/"},{"title":"memcached在Linux下的安装","text":"安装环境：系统是 centos6.5 libevent安装打开memcached官网的下载界面http://memcached.org/downloads，看到有如下提示： Debian/Ubuntu: apt-get install libevent-dev Redhat/Centos: yum install libevent-devel 说明memcached依赖于libevent 。 yum安装1yum install libevent-devel 源码安装下载网址：http://libevent.org/123456#解压 tar -zxvf libevent-2.0.22-stable.tar.gz #配置 ./configure –prefix=/usr/local/libevent #安装 make &amp;&amp; make install 下载memcachedmemcached下载网址： http://memcached.org/downloads 或者 wget http://memcached.org/latest 解压该版本的memcached没有使用gzip压缩，所以不能加-g1tar -xvf memcached-1.4.25.tar.gz 编译通过 ./configure –help可以参考编译参数，可以看出，我们可以通过 –with-libevent来指定libevent安装目录。 编译命令如下：1./configure --prefix=/usr/local/memcached --with-libevent=/usr/local/libevent/ 安装执行如下命令1make &amp;&amp; make install 安装完成后，可以看到/usr/local目录下多了一个memcached目录。 启动1./memcached -vv -u nobody","link":"/2017/03/18/Database/memcached在Linux下的安装/"},{"title":"Oracle在Linux下的安装","text":"安装环境：系统是 centos6.5","link":"/2017/03/18/Database/Oracle在Linux下的安装/"},{"title":"Redis在Linux下的安装","text":"基本知识1、 Redis的数据类型：字符串、列表（lists）、集合（sets）、有序集合（sorts sets）、哈希表（hashs） 2、 Redis和memcache相比的独特之处：（1）redis可以用来做存储（storge）、而memcache是来做缓存（cache）。这个特点主要是因为其有“持久化”功能（2）存储的数据有“结构”，对于memcache来说，存储的数据，只有一种类型——“字符串”，而redis则可以存储字符串、链表、集合、有序集合、哈序结构 3、 持久化的两种方式：Redis将数据存储于内存中，或被配置为使用虚拟内存。实现数据持久化的两种方式：（1）使用截图的方式，将内存中的数据不断写入磁盘（性能高，但可能会引起一定程度的数据丢失）（2）使用类似mysql的方式，记录每次更新的日志 4、 Redis的主从同步：对提高读取性能非常有益 5、Redis服务端的默认端口是6379 下载安装环境：系统是 centos6.5 下载地址：http://download.redis.io/releases/redis-3.2.1.tar.gz上传到Linux。 解压1tar -zxvf redis-3.2.1.tar.gz 编译源程序123456cd redis-3.2.1make#编译完成之后cd srcmake install PREFIX=/usr/local/redis 配置文件1cp redis.conf /usr/local/redis/bin/ 服务启动和停止12cd /usr/local/redis/bin/./redis-server redis.conf 默认情况，Redis不是在后台运行，我们需要把redis放在后台运行123vim redis.conf#将daemonize的值改为yesdaemonize yes 客户端连接1./redis-cli 停止服务1./redis-cli shutdown redis开机自启123vim /etc/rc.local#加入redis启动脚本/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.conf 其他redis-benchmark：redis性能测试工具 redis-check-aof：检查aof日志的工具 redis-check-dump：检查rdb日志的工具 redis-cli：连接用的客户端 redis-server：redis服务进程 Redis的配置daemonize：如需要在后台运行，把该项的值改为yes pdifile：把pid文件放在/var/run/redis.pid，可以配置到其他地址 bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项 port：监听端口，默认为6379 timeout：设置客户端连接时的超时时间，单位为秒 loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启notice logfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上 database：设置数据库的个数，默认使用的数据库是0 save：设置redis进行数据库镜像的频率 rdbcompression：在进行镜像备份时，是否进行压缩 dbfilename：镜像备份文件的文件名 dir：数据库镜像备份的文件放置的路径 slaveof：设置该数据库为其他数据库的从数据库 masterauth：当主数据库连接需要密码验证时，在这里设定 requirepass：设置客户端连接后进行任何其他指定前需要使用的密码 maxclients：限制同时连接的客户端数量 maxmemory：设置redis能够使用的最大内存 appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态 appendfsync：设置appendonly.aof文件进行同步的频率 vm_enabled：是否开启虚拟内存支持 vm_swap_file：设置虚拟内存的交换文件的路径 vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0 vm_page_size：设置虚拟内存页的大小 vm_pages：设置交换文件的总的page数量 vm_max_thrrads：设置vm IO同时使用的线程数量","link":"/2017/03/18/Database/Redis在Linux下的安装/"},{"title":"Oracle查看表空间常用语句","text":"查看表空间使用率12345678910111213select a.tablespace_name, a.bytes / 1024 / 1024 \"Sum MB\", (a.bytes - b.bytes) / 1024 / 1024 \"used MB\", b.bytes / 1024 / 1024 \"free MB\", round(((a.bytes - b.bytes) / a.bytes) * 100, 2) \"percent_used\" from (select tablespace_name, sum(bytes) bytes from dba_data_files group by tablespace_name) a, (select tablespace_name, sum(bytes) bytes, max(bytes) largest from dba_free_space group by tablespace_name) b where a.tablespace_name = b.tablespace_name order by ((a.bytes - b.bytes) / a.bytes) desc 查看用户、表空间使用率123456789101112select a.username,b.* from dba_users a left join (select a.tablespace_name, a.bytes / 1024 / 1024 \"Sum MB\", (a.bytes - b.bytes) / 1024 / 1024 \"used MB\", b.bytes / 1024 / 1024 \"free MB\", round(((a.bytes - b.bytes) / a.bytes) * 100, 2) \"percent_used\" from (select tablespace_name, sum(bytes) bytes from dba_data_files group by tablespace_name) a, (select tablespace_name, sum(bytes) bytes, max(bytes) largest from dba_free_space group by tablespace_name) b where a.tablespace_name = b.tablespace_name) b on a.default_tablespace = b.tablespace_name; 删除用户和数据文件12345--步骤一： 删除userdrop user ×× cascade--说明： 删除了user，只是删除了该user下的schema objects，是不会删除相应的tablespace的。--步骤二： 删除tablespaceDROP TABLESPACE tablespace_name INCLUDING CONTENTS AND DATAFILES; 改变数据文件大小1alter database datafile '/u01/oracle/oradata/aeye/sysaux01.dbf' resize 2G;","link":"/2017/05/30/Database/Oracle查看表空间常用语句/"},{"title":"mysql事件（计划任务）","text":"例子：123456789101112131415161718192021222324252627282930313233343536373839DELIMITER $$-- 1、设置 全局变量event_scheduler开启，使用event必须开启-- SET GLOBAL event_scheduler = ON$$ -- required for event to execute but not create CREATE /*[DEFINER = { user | CURRENT_USER }]*/ EVENT `start_distribution`.`event_account_checking` ON SCHEDULE EVERY 1 DAY STARTS '2017-09-04 06:00:00' ON COMPLETION NOT PRESERVE ENABLE COMMENT '每天自动统计对账数据' /* uncomment the example below you want to use */ -- scheduleexample 1: run once 执行一次 -- AT 'YYYY-MM-DD HH:MM.SS'/CURRENT_TIMESTAMP { + INTERVAL 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] } -- scheduleexample 2: run at intervals forever after creation 创建后每多久执行一次 -- EVERY 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] -- scheduleexample 3: specified start time, end time and interval for execution 指定开始开始、结束时间和间隔时间执行任务。 /*EVERY 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] STARTS CURRENT_TIMESTAMP/'YYYY-MM-DD HH:MM.SS' { + INTERVAL 1[HOUR|MONTH|WEEK|DAY|MINUTE|...] } ENDS CURRENT_TIMESTAMP/'YYYY-MM-DD HH:MM.SS' { + INTERVAL 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] } */ /*[ON COMPLETION [NOT] PRESERVE] -- 执行后删除(NOT)还是保留 [ENABLE | DISABLE] -- 创建时，event的章台 [COMMENT 'comment']*/ -- 注释DO BEGIN call pro_account_checking(); END$$DELIMITER ;","link":"/2017/09/04/Database/mysql事件（计划任务）/"},{"title":"mysql在Linux下的安装","text":"安装环境：系统是 centos6.5 下载下载地址：http://dev.mysql.com/downloads/mysql/5.6.html#downloads下载版本：我这里选择的5.6.33，通用版，linux下64位 也可以直接复制64位的下载地址，通过命令下载：wget http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.33-linux-glibc2.5-x86_64.tar.gz 解压1234#解压tar -zxvf mysql-5.6.33-linux-glibc2.5-x86_64.tar.gz#复制解压后的mysql目录cp -r mysql-5.6.33-linux-glibc2.5-x86_64 /usr/local/mysql 添加用户组和用户1234#添加用户组groupadd mysql#添加用户mysql 到用户组mysqluseradd -g mysql mysql 安装1234567891011121314151617181920212223242526272829303132cd /usr/local/mysql/mkdir ./data/mysqlchown -R mysql:mysql ././scripts/mysql_install_db --user=mysql --datadir=/usr/local/mysql/data/mysqlcp support-files/mysql.server /etc/init.d/mysqldchmod 755 /etc/init.d/mysqldcp support-files/my-default.cnf /etc/my.cnf#修改启动脚本vi /etc/init.d/mysqld #修改项：basedir=/usr/local/mysql/datadir=/usr/local/mysql/data/mysql #启动服务service mysqld start #测试连接./mysql/bin/mysql -uroot #加入环境变量，编辑 /etc/profile，这样可以在任何地方用mysql命令了export PATH=$PATH:/usr/local/mysql//binsource /etc/profile #启动mysqlservice mysqld start#关闭mysqlservice mysqld stop#查看运行状态service mysqld status 错误sqlyog连接时，报1130错误.是由于没有给远程连接的用户权限问题解决1:更改 ‘mysql’数据库‘user’表‘host’项，从‘localhost’改成‘%’。1234use mysql;select 'host' from user where user='root'; update user set host = '%' where user ='root';flush privileges; 解决2：直接授权1GRANT ALL PRIVILEGES ON *.* TO ‘root’@'%’ IDENTIFIED BY ‘youpassword’ WITH GRANT OPTION; 安装时的一些错误-bash: ./scripts/mysql_install_db: /usr/bin/perl: bad interpreter: 没有那个文件或目录1解决： yum -y install perl perl-devel Installing MySQL system tables…./bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory1解决：yum -y install libaio-devel #其他 配置环境变量12vi + /etc/profileexport PATH=....:/usr/local/mysql/bin Linux表名大小写问题编辑/etc/my.cnf,在[mysqld]下面添加如下：12[mysqld]lower_case_table_names=1 乱码问题编辑/etc/my.cnf,在[mysqld]下面添加如下：123[mysqld]...character-set-server=utf8","link":"/2017/03/18/Database/mysql在Linux下的安装/"},{"title":"FreeMarker简单介绍","text":"","link":"/2017/05/30/Java/FreeMarker简单介绍/"},{"title":"mysql存储过程","text":"简介存储过程是可编程的函数，在数据库中创建并保存，可以由SQL语句和控制结构组成。当想要在不同的应用程序或平台上执行相同的函数，或者封装特定功能时，存储过程是非常有用的。数据库中的存储过程可以看做是对编程中面向对象方法的模拟，它允许控制数据的访问方式。 存储过程是数据库的一个重要的功能，MySQL 5.0以前并不支持存储过程，这使得MySQL在应用上大打折扣。好在MySQL 5.0开始支持存储过程，这样即可以大大提高数据库的处理速度，同时也可以提高数据库编程的灵活性。 存储过程的优点(1).增强SQL语言的功能和灵活性：存储过程可以用控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 (2).标准组件式编程：存储过程被创建后，可以在程序中被多次调用，而不必重新编写该存储过程的SQL语句。而且数据库专业人员可以随时对存储过程进行修改，对应用程序源代码毫无影响。 (3).较快的执行速度：如果某一操作包含大量的Transaction-SQL代码或分别被多次执行，那么存储过程要比批处理的执行速度快很多。因为存储过程是预编译的。在首次运行一个存储过程时查询，优化器对其进行分析优化，并且给出最终被存储在系统表中的执行计划。而批处理的Transaction-SQL语句在每次运行时都要进行编译和优化，速度相对要慢一些。 (4).减少网络流量：针对同一个数据库对象的操作（如查询、修改），如果这一操作所涉及的Transaction-SQL语句被组织进存储过程，那么当在客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而大大减少网络流量并降低了网络负载。 (5).作为一种安全机制来充分利用：通过对执行某一存储过程的权限进行限制，能够实现对相应的数据的访问权限的限制，避免了非授权用户对数据的访问，保证了数据的安全。 例子1234567891011121314151617181920212223242526272829303132333435363738394041424344DELIMITER $$ USE `start_user`$$ DROP PROCEDURE IF EXISTS `rob_test`$$ CREATE /*[DEFINER = { user | CURRENT_USER }]*/ -- 0、定义存储过程名称和参数、返回值 -- in 为输入参数；out 为返回值，inout 即是参数也是返回值 PROCEDURE `start_user`.`rob_test`( out msg VARCHAR(50) ) /* LANGUAGE SQL | [NOT] DETERMINISTIC | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } | SQL SECURITY { DEFINER | INVOKER } | COMMENT 'string' */ BEGIN -- 1、声明变量 DECLARE userId int; DECLARE i int; DECLARE phoneId BIGint; -- 2、赋值，也可以用DEFAULT，如：DECLARE i int DEFAULT 0; SET i=0; SET phoneId= 11010000002; -- 3、业务逻辑，此处用循环插入数据 while i&lt;5 do INSERT INTO `start_user`.`user` (`nickName`, `gender`, `mobile`, `signatureText`, `avatarUrl`, `userType`, `isUserGroup`, `status`, `channel`, `inviteGuestPermission`, `reported`, `flag`, `appId`, `loginBundleId`) VALUES(CONCAT('机器人',i),'MALE',CONCAT(phoneId,''),NULL,NULL,'NORMAL',NULL,'1',NULL,NULL,NULL,NULL,NULL,NULL); SELECT LAST_INSERT_ID() INTO userId ; insert into `start_distribution`.`dis_org_startuser` ( `orgId`, `agentId`, `cooperatorId`, `opcenterId`, `startUserId`, `startUserType`, `inviteUserId`) values('999992348','999992347','999992346','999992345',userId,'ANCHOR',NULL); set i=i+1; set phoneId= phoneId+1; end while; -- 4、结束循环，设定返回值 set msg ='执行成功'; END$$DELIMITER ; 语法CREATE PROCEDURE 过程名([[IN|OUT|INOUT] 参数名 数据类型[,[IN|OUT|INOUT] 参数名 数据类型…]]) [特性 …] 过程体 结束符DELIMITER 定义语句结束符。首先将结束符变为“$$”,在完成存储过程之后再将结束符改为默认的“;”。 参数存储过程根据需要可能会有输入、输出、输入输出参数，如果有多个参数用”,”分割开。MySQL存储过程的参数用在存储过程的定义，共有三种参数类型,IN,OUT,INOUT: IN：参数的值必须在调用存储过程时指定，在存储过程中修改该参数的值不能被返回，为默认值OUT:该值可在存储过程内部被改变，并可返回INOUT:调用时指定，并且可被改变和返回 过程体过程体的开始与结束使用BEGIN与END进行标识。 变量赋值语法：SET 变量名 = 变量值 [,变量名= 变量值 …] 用户变量用户变量一般以@开头注意：滥用用户变量会导致程序难以理解及管理 注释MySQL存储过程可使用两种风格的注释：双杠：–，该风格一般用于单行注释C风格： 一般用于多行注释 调用用call和你过程名以及一个括号，括号里面根据需要，加入参数，参数包括输入参数、输出参数、输入输出参数。 控制语句条件语句IF-THEN-ELSE语句1234567891011121314151617DROP PROCEDURE IF EXISTS proc3;DELIMITER //CREATE PROCEDURE proc3(IN parameter int) BEGIN DECLARE var int; SET var=parameter+1; IF var=0 THEN INSERT INTO t VALUES (17); END IF ; IF parameter=0 THEN UPDATE t SET s1=s1+1; ELSE UPDATE t SET s1=s1+2; END IF ; END ; //DELIMITER ; CASE-WHEN-THEN-ELSE语句12345678910111213141516DELIMITER // CREATE PROCEDURE proc4 (IN parameter INT) BEGIN DECLARE var INT; SET var=parameter+1; CASE var WHEN 0 THEN INSERT INTO t VALUES (17); WHEN 1 THEN INSERT INTO t VALUES (18); ELSE INSERT INTO t VALUES (19); END CASE ; END ; //DELIMITER ; 循环语句WHILE-DO…END-WHILE123456789101112DELIMITER // CREATE PROCEDURE proc5() BEGIN DECLARE var INT; SET var=0; WHILE var&lt;6 DO INSERT INTO t VALUES (var); SET var=var+1; END WHILE ; END; //DELIMITER ; REPEAT…END REPEAT此语句的特点是执行操作后检查结果12345678910111213DELIMITER // CREATE PROCEDURE proc6 () BEGIN DECLARE v INT; SET v=0; REPEAT INSERT INTO t VALUES(v); SET v=v+1; UNTIL v&gt;=5 END REPEAT; END; //DELIMITER ; LOOP…END LOOP12345678910111213141516171819202122232425DELIMITER // CREATE PROCEDURE proc7 () BEGIN DECLARE v INT; SET v=0; LOOP_LABLE:LOOP INSERT INTO t VALUES(v); SET v=v+1; IF v &gt;=5 THEN LEAVE LOOP_LABLE; END IF; END LOOP; END; //DELIMITER ;``` #### LABLES标号标号可以用在begin repeat while 或者loop 语句前，语句标号只能在合法的语句前面使用。可以跳出循环，使运行指令达到复合语句的最后一步。#### ITERATE迭代通过引用复合语句的标号,来从新开始复合语句### ITERATE DELIMITER // CREATE PROCEDURE proc8() BEGIN DECLARE v INT; SET v=0; LOOP_LABLE:LOOP IF v=3 THEN SET v=v+1; ITERATE LOOP_LABLE; END IF; INSERT INTO t VALUES(v); SET v=v+1; IF v&gt;=5 THEN LEAVE LOOP_LABLE; END IF; END LOOP; END; //DELIMITER ;```","link":"/2017/08/18/Database/mysql存储过程/"},{"title":"Java配置中心","text":"阿里：Diamondhttps://github.com/hengyunabc/xdiamondhttps://yq.aliyun.com/articles/6058 携程：Apollohttps://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8Dhttps://github.com/ctripcorp/apollo/wiki/Quick-Start Spring: Spring Cload Confighttps://github.com/spring-cloud/spring-cloud-config","link":"/2017/08/08/Java/Java配置中心/"},{"title":"Logger4j详解","text":"一、介绍Log4j是Apache的一个开源项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件、甚至是套接口服务 器、NT的事件记录器、UNIX Syslog守护进程等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。Log4j由三个重要的组件构成：日志信息的优先级（Loggers），日志信息的输出目的地（Appenders），日志信息的输出格式（Layouts）。日志信息的优先级从高到低有ERROR、WARN、 INFO、DEBUG，分别用来指定这条日志信息的重要程度；日志信息的输出目的地指定了日志将打印到控制台还是文件中；而输出格式则控制了日志信息的显示内容。 二、配置文件其实您也可以完全不使用配置文件，而是在代码中配置Log4j环境。但是，使用配置文件将使您的应用程序更加灵活。Log4j支持两种配置文件格式，一种是XML格式的文件，一种是properties格式的文件。下面我们介绍使用properties格式做为配置文件的方法：示例：log4j.rootLogger=INFO, A1log4j.appender.A1=org.apache.log4j.ConsoleAppenderlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n 1. 配置根Logger，其语法为：log4j.rootLogger = [ level ] , appenderName, appenderName, …其中，level 是日志记录的优先级，分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者您定义的级别。Log4j建议只使用四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来。 appenderName就是指定日志信息输出到哪个地方。您可以同时指定多个输出目的地。 2. 配置日志信息输出目的地Appender，其语法为：log4j.appender.appenderName = package+appender_class_namelog4j.appender.appenderName.option1 = value1…log4j.appender.appenderName.option = valueN其中，Log4j提供的appender有以下几种：org.apache.log4j.ConsoleAppender（控制台），org.apache.log4j.FileAppender（文件），org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方) org.apache.log4j.jdbc.JDBCAppender(将日志写入数据库) (1).ConsoleAppender选项Threshold=WARN:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。Target=System.err：默认情况下是：System.out,指定输出控制台(2).FileAppender 选项Threshold=WARN:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。(3).DailyRollingFileAppender 选项Threshold=WARN:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。DatePattern=’.’yyyy-ww:每周滚动一次文件，即每周产生一个新的文件。当然也可以指定按月、周、天、时和分。即对应的格式如下：1)’.’yyyy-MM: 每月2)’.’yyyy-ww: 每周3)’.’yyyy-MM-dd: 每天4)’.’yyyy-MM-dd-a: 每天两次5)’.’yyyy-MM-dd-HH: 每小时6)’.’yyyy-MM-dd-HH-mm: 每分钟(4).RollingFileAppender 选项Threshold=WARN:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。MaxFileSize=100KB: 后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。MaxBackupIndex=2:指定可以产生的滚动文件的最大数。 (5). JDBCApperder选项 URL=jdbc:mysql://localhost:3306/test：指定日志写入的数据库链接driver=com.mysql.jdbc.Driver：指定数据库驱动user=root：指定数据库的用户名password=123：指定数据库的登录密码sql=insert into tb_log (message) values(‘=[%-5p] %d(%r) –&gt; [%t] %l: %m %x %n’)：指定写入数据库的执行语句 3. 配置日志信息的布局，其语法为：log4j.appender.appenderName.layout = package+layout_class_namelog4j.appender.appenderName.layout.option1 = value1…log4j.appender.appenderName.layout.option = valueN其中，Log4j提供的layout有以下几种：org.apache.log4j.HTMLLayout（以HTML表格形式布局），org.apache.log4j.PatternLayout（可以灵活地指定布局模式），org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 4、输出格式设置在配置文件中可以通过log4j.appender.A1.layout.ConversionPattern设置日志输出格式。参数：%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,%d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921 %r: 输出自应用启动到输出该log信息耗费的毫秒数%c: 输出日志信息所属的类目，通常就是所在类的全名%t: 输出产生该日志事件的线程名%l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10) %x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。%%: 输出一个”%”字符%F: 输出日志消息产生时所在的文件名称%L: 输出代码中的行号%m: 输出代码中指定的消息,产生的日志具体信息%n: 输出一个回车换行符，Windows平台为”\\r\\n”，Unix平台为”\\n”输出日志信息换行可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如：1)%20c：指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐。2)%-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，”-”号指定左对齐。3)%.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格。4)%20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边交远销出的字符截掉。 三、如何在不同的模块中输出不同的日志用户基础信息模块路径为：com.test.user它下面有个类：com.test.user.service.impl.UserInfoprivate Log log = LogFactory.getLog(UserInfo.class); 方法1：在log4j.properties中加入:log4j.logger.com.test.user=info,userLog,stdoutlog4j.appender.userLog=org.apache.log4j.FileAppenderlog4j.appender.userLog.File=../logs/userinfo.loglog4j.appender.userLog.Append=truelog4j.appender.userLog.Threshold=infolog4j.appender.userLog.layout=org.apache.log4j.PatternLayoutlog4j.appender.userLog.layout.ConversionPattern==%d %p [%c] - %m%n 注：也就是让com.test.user模块下所有的logger使用log4j.appender.userLog所做的配置。 方法2：自定义“别名”private Log log = LogFactory.getLog(“userInfoLog”);然后在log4j.properties中加入:log4j.logger.userInfoLog=info,userLog,stdoutlog4j.appender.userLog=org.apache.log4j.FileAppenderlog4j.appender.userLog.File=../logs/userinfo.loglog4j.appender.userLog.Append=truelog4j.appender.userLog.Threshold=infolog4j.appender.userLog.layout=org.apache.log4j.PatternLayoutlog4j.appender.userLog.layout.ConversionPattern==%d %p [%c] - %m%n 注：也就是在用logger时给它一个自定义的名字(如这里的”userInfoLog”)，然后在log4j.properties中做出相应配置即可。，在这种模式下，即使在同一个类中也能定义多个不同输出的log. 在类中调用代码如下：private Log loggerError = LogFactory.getLog(“userErrorLog”);private Log loggerInfo = LogFactory.getLog(“userInfoLog”); 自定义的日志默认是同时输出到log4j.rootLogger所配置的日志中的，如何能只让它们输出到自己指定的日志中呢？log4j.additivity.userInfoLog = false它用来设置是否同时输出到log4j.rootLogger所配置的日志中，设为false就不会输出到其它地方啦！注意这里的”userInfoLog”是你在程序中给logger起的那个自定义的名字！如果你说，我只是不想同时输出这个日志到log4j.rootLogger所配置的logfile中，stdout里我还想同时输出呢！如：log4j.logger.userInfoLog=DEBUG, userLog, stdout 三、加载log4j.properties文件1、spring方式加载，配置与web.xml中：Spring加载log4j.properties，它提供了一个Log4jConfigListener，本身就能通过web.xml配置从指定位置加载log4j配置文件和log4j的输出路径，要注意的是 Log4jConfigListener必须要在Spring的Listener之前。 web.xml12345678910111213141516171819202122232425&lt;!-- 设置由Spring载入的Log4j配置文件位置 --&gt;&lt;context-param&gt;&lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt;&lt;param-value&gt;WEB-INF/classes/log4j.properties&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- Spring刷新Log4j配置文件变动的间隔,单位为毫秒 --&gt;&lt;context-param&gt;&lt;param-name&gt;log4jRefreshInterval&lt;/param-name&gt;&lt;param-value&gt;10000&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt;&lt;/listener&gt; 2、可以通过资源类对资源文件进行加载，与使用为一体123456789public class Logger4JTest { public static void main(String[] args) { PropertyConfigurator.configure(\" D:/log/log4j.properties \"); Logger logger = Logger.getLogger(Logger4JTest.class); logger.debug(\" debug \"); logger.error(\" error \"); } } 四、在程序中的使用在程序中使用Log4j之前，首先要将commons-logging.jar和logging-log4j-1.2.9.jar导入到classpath中，并将log4j.properties放于src根目录中。接下来就可以使用了。 1.得到记录器使用Log4j，第一步就是获取日志记录器，这个记录器将负责控制日志信息。其语法为：public static Logger getLogger( String name)，通过指定的名字获得记录器，如果必要的话，则为这个名字创建一个新的记录器。Name一般取本类的名字，比如：static Logger logger = Logger.getLogger ( ServerWithLog4j.class.getName () ) ; 2.插入记录信息（格式化日志信息）当上两个必要步骤执行完毕，您就可以轻松地使用不同优先级别的日志记录语句插入到您想记录日志的任何地方，其语法如下：logger.debug ( Object message ) ;logger.info ( Object message ) ;logger.warn ( Object message ) ;logger.error ( Object message ) ;","link":"/2017/12/27/Java/Logger4j详解/"},{"title":"Velocity简单介绍","text":"","link":"/2017/05/30/Java/Velocity简单介绍/"},{"title":"NIO框架的一点想法","text":"不管是什么NIO框架。本身其实都是对Java底层的一种在封装。封装一套更简便，更易于扩展的一套东西以方便开发者使用。所以性能上也许会有所差异，但是绝对没有java和C++之间这么多。(代码写的太烂的除外，不过想要使用java写出很烂的代码也比较困难。)这些框架在性能方面差别不会超过1%。 Mina和Netty开始。因为这两个NIO框架的创作者是同一个人Trustin Lee （韩国人）。GitHub主页地址 ：https://github.com/trustin。尽管创作者现在已经不专注与开发了。但是框架的后续开发和继承，可以说都是符合最开始的设定的。两个框架的架构设计思路基本一致。 Netty从某种程度上讲是Mina的延伸和扩展。解决了一些Mina上的设计缺陷，也优化了一下Mina上面的设计理念。 另一方面Netty相比较Mina更容易学习。API更简单。详细的范例源码和API文档。更活跃的论坛和社区。更高的代码更新维护速度。 我想不出什么理由来不选择Netty。 xSocket：是一个轻量级的基于nio的服务器框架用于开发高性能、可扩展、多线程的服务器。该框架封装了线程处理、异步读/写等方面。（只是对Java的NIO做了最简单的封装，以便于开发使用。） Grizzly ： 是一种应用程序框架，专门解决编写成千上万用户访问服务器时候产生的各种问题。使用JAVA NIO作为基础，并隐藏其编程的复杂性。容易使用的高性能的API。带来非阻塞socketd到协议处理层。利用高性能的缓冲和缓冲管理使用高性能的线程池。","link":"/2017/12/27/Java/NIO框架的一点想法/"},{"title":"idea的使用","text":"1 修改对应的配置信息(缓存)地址由于我家里的电脑C盘被我设置得超级小,然后Idea默认的各种系统配置,最主要是缓存的地址,修改 ${idea.home}/bin/idea.properties 修改下面几个值. 123456789101112131415. #--------------------------------------------------------------------- 16. # Uncomment this option if you want to customize path to IDE config folder. Make sure you're using forward slashes 17. #--------------------------------------------------------------------- 18. idea.config.path=D:/dev_soft/IntelliJ IDEA 12.0.1/bin/.IntelliJIdea/config 19. 20. #--------------------------------------------------------------------- 21. # Uncomment this option if you want to customize path to IDE system folder. Make sure you're using forward slashes 22. #--------------------------------------------------------------------- 23. idea.system.path=D:/dev_soft/IntelliJ IDEA 12.0.1/bin/.IntelliJIdea/system 24. 25. #--------------------------------------------------------------------- 26. # Uncomment this option if you want to customize path to user installed plugins folder. Make sure you're using forward slashes 27. #--------------------------------------------------------------------- 28. idea.plugins.path=D:/dev_soft/IntelliJ IDEA 12.0.1/bin/.IntelliJIdea/config/plugins 2 修改快捷键 key/map 选择eclipse ,选择copy成自定义 (我还是习惯用eclipse的快捷键) 3 配置修改1、修改主题 File | Settings | Appearance &amp; Behavior | Appearance ： Theme选择 Darcula2、显示行号：Settings-&gt;Editor-&gt;Appearance标签项，勾选Show line numbers3、选择字体大小：File | Settings | Editor | Font 154、Tab换成字符串 ：File | Settings | Editor | Code Style | Java –&gt; Use tab charactor3、生成Serializable ID ，setting–&gt;Editor–&gt;Inspactions–&gt;Java | Serialization issues | Serializable class without ‘serialVersionUID’ 打上勾4、maven 工程 unable to read the metadata file for artifact 问题 :setting-&gt;maven-&gt;always update snapshot 打开,然后重新import change就搞定了. 4、代码TemplatesFile | Settings | Editor | File and Code Templates –&gt; Includes–&gt;File Header/** Company：MGTV User: huangmin DateTime: ${DATE} ${TIME}*/ File | Settings | Editor | Live Templates添加Templates group ，再添加 Live Template。private static final Logger LOGGER = LoggerFactory.getLogger($CLASS$.class);点击$CLASS$ ，点击edit variables，选择getClassName() 5、常用插件Mybatis自动转换对象插件 generateO2O 快捷键 alt+insert 快捷键提示插件Key Promoter大小写转换插件 UpperLowerCapitalize : 安装后快捷键alt+P全部大写 alt+L全部小写 alt+C开头字母大写查看maven的依赖树 Maven Helper 6、常用快捷键fori/sout/psvm+Tab.for+Tab.var+Tab Top #10切来切去：Ctrl+TabTop #9选你所想：Ctrl+WTop #8代码生成：Template/Postfix +TabTop #7发号施令：Ctrl+Shift+ATop #6无处藏身：Shift+ShiftTop #5自动完成：Ctrl+Shift+EnterTop #4创造万物：Alt+Insert 太难割舍，前三名并列吧！Top #1智能补全：Ctrl+Shift+SpaceTop #1自我修复：Alt+EnterTop #1重构一切：Ctrl+Shift+Alt+T","link":"/2017/12/05/Java/idea的使用/"},{"title":"Centos7.3防火墙配置","text":"firewall防火墙1、查看firewall服务状态123456789101112131415查看状态： systemctl status firewalld 启动： systemctl start firewalld停止： systemctl stop firewalld禁用： systemctl enable firewalld启用： systemctl disable firewalld启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed 2、查看firewall的状态1firewall-cmd --state 3、开启、重启、关闭、firewalld.service服务123456# 开启service firewalld start# 重启service firewalld restart# 关闭service firewalld stop 4、查看防火墙规则123456789101112firewall-cmd --list-all -zone=public查看版本： firewall-cmd --version查看帮助： firewall-cmd --help显示状态： firewall-cmd --state查看所有打开的端口： firewall-cmd --zone=public --list-ports更新防火墙规则： firewall-cmd --reload查看区域信息: firewall-cmd --get-active-zones查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0拒绝所有包：firewall-cmd --panic-on取消拒绝状态： firewall-cmd --panic-off查看是否拒绝： firewall-cmd --query-panic 5、查询、开放、关闭端口 12345678# 查询端口是否开放firewall-cmd --query-port=8080/tcp # 开放80端口firewall-cmd --permanent --add-port=80/tcp -zone=public# 移除端口firewall-cmd --permanent --remove-port=8080/tcp -zone=public#重启防火墙(修改配置后要重启防火墙)firewall-cmd --reload 参数解释1、firwall-cmd：是Linux提供的操作firewall的一个工具；2、–permanent：表示设置为持久；3、–add-port：标识添加的端口； iptables防火墙1、安装123sudo yum install iptables-servicessudo systemctl enable iptables &amp;&amp; sudo systemctl enable ip6tablessudo systemctl start iptables &amp;&amp; sudo systemctl start ip6tables 2、启用、禁用1234 #最后重启防火墙使配置生效systemctl restart iptables.service# 设置防火墙开机启动systemctl enable iptables.service 3、编辑配置文件1vi /etc/sysconfig/iptables 12345678910111213141516# sampleconfiguration for iptables service# you can edit thismanually or use system-config-firewall# please do not askus to add additional ports/services to this default configuration*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT[0:0]:OUTPUT ACCEPT[0:0]-A INPUT -m state--state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -jACCEPT-A INPUT -i lo -jACCEPT-A INPUT -p tcp -mstate --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -jACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8080-j ACCEPT-A INPUT -j REJECT--reject-with icmp-host-prohibited-A FORWARD -jREJECT --reject-with icmp-host-prohibitedCOMMIT 4、开启、停止123456# 查看防火墙状态： service iptables status# 开启防火墙：service iptables start# 关闭防火墙：service iptables stop","link":"/2018/01/02/Linux/Centos7.3防火墙配置/"},{"title":"Linux时间和时区","text":"如果你的 Linux 系统时区配置不正确，必需要手动调整到正确的当地时区。NTP 对时间的同步处理只计算当地时间与 UTC 时间的偏移量，因此配置一个 NTP 对时间进行同步并不能解决时区不正确的问题。所以大家在用了国外云计算服务商如 Microsoft Azure 或其它 VPS、虚拟机时，需要注意是否与中国大陆的时区一致。 时间123456# 查询时间date# 修改时间date -s \"2018-01-03 15:36:25\"# 查看时区时间ls -l /etc/localtime 时区/etc/localtime是用来描述本机时间，而 /etc/timezone是用来描述本机所属的时区.1234# 修改时区tzselect# 查看时区timedatectl Linux 用户一个多用户系统，每个用户都可以配置自己所需的时区，你可以为自己新增一个 TZ 环境变量：1export TZ='Asia/Shanghai' 执行完成之后需要重新登录系统或刷新 ~/.bashrc 生效。1source ~/.bashrc 更改Linux系统时区要更改 Linux 系统整个系统范围的时区可以使用如下命令：12sudo rm -f /etc/localtimesudo ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 注意：/usr/share/zoneinfo/Asia/Shanghai 中的具体时区请用自己获取到的 TZ 值进行替换。","link":"/2018/01/03/Linux/Linux时间和时区/"},{"title":"Integer源码分析","text":"","link":"/2018/10/24/javase/Integer源码分析/"},{"title":"Nginx在Linux下的安装","text":"系统平台：CentOS release 6.6 (Final) 64位。 安装编译工具及库文件1yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 首先要安装 PCREPCRE 作用是让 Nginx 支持 Rewrite 功能。 1、下载 PCRE 安装包，下载地址： http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz1[root@ngnix src]# wget http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz 2、解压安装包:1[root@ngnix src]# tar zxvf pcre-8.35.tar.gz 3、进入安装包目录1[root@ngnix src]# cd pcre-8.35 4、编译安装12[root@ngnix pcre-8.35]# ./configure[root@ngnix pcre-8.35]# make &amp;&amp; make install 5、查看pcre版本1[root@ngnix pcre-8.35]# pcre-config --version 安装Nginx1、下载 Nginx，下载地址：http://nginx.org/download/nginx-1.6.2.tar.gz1[root@ngnix src]# wget http://nginx.org/download/nginx-1.6.2.tar.gz 2、解压安装包1[root@ngnix src]# tar zxvf nginx-1.6.2.tar.gz 3、进入安装包目录1[root@ngnix src]# cd nginx-1.6.2 4、编译安装123[root@ngnix nginx-1.6.2]# ./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.35[root@ngnix nginx-1.6.2]# make[root@ngnix nginx-1.6.2]# make install 5、查看nginx版本1[root@ngnix nginx-1.6.2]# /usr/local/webserver/nginx/sbin/nginx -v 到此，nginx安装完成。 Nginx 配置创建 Nginx 运行使用的用户 www：12[root@ngnix conf]# /usr/sbin/groupadd www [root@ngnix conf]# /usr/sbin/useradd -g www www 配置nginx.conf ，将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容1[root@ngnix conf]# cat /usr/local/webserver/nginx/conf/nginx.conf 显示如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374user www www;worker_processes 2; #设置值和CPU核心数一致error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别pid /usr/local/webserver/nginx/nginx.pid;#Specifies the value for maximum file descriptors that can be opened by this process.worker_rlimit_nofile 65535;events{ use epoll; worker_connections 65535;}http{ include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for'; #charset gb2312; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/html text/xml text/javascript application/x-javascript application/javascript text/css text/plain image/png image/jpeg image/gif; gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #下面是server虚拟主机的配置 server { listen 80;#监听端口 server_name localhost;#域名 index index.html index.htm index.php; root /usr/local/webserver/nginx/html;#站点目录 location ~ .*\\.(php|php5)?$ { #fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|ico)$ { expires 30d; # access_log off; } location ~ .*\\.(js|css)?$ { expires 15d; # access_log off; } access_log off; }} 检查配置文件ngnix.conf的正确性命令：1[root@ngnix conf]# /usr/local/webserver/nginx/sbin/nginx -t Nginx命令1234/usr/local/webserver/nginx/sbin/nginx # 启动 Nginx/usr/local/webserver/nginx/sbin/nginx -s reload # 重新载入配置文件/usr/local/webserver/nginx/sbin/nginx -s reopen # 重启 Nginx/usr/local/webserver/nginx/sbin/nginx -s stop # 停止 Nginx","link":"/2017/12/15/server/Nginx安装/"},{"title":"Nginx配置文件详解","text":"Nginx配置文件nginx.conf中文详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /usr/local/nginx/logs/error.log info;#进程pid文件pid /usr/local/nginx/logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接数上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。worker_rlimit_nofile 65535;events{ #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on;} #设定http服务器，利用它的反向代理功能提供负载均衡支持http{ #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream piao.jd.com { #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; } #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #upstream bakend { # server 192.168.0.14; # server 192.168.0.15; #} #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend { # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #} #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend { # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #} #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend { # server server1; # server server2; # fair; #} #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend { # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #} #tips: #upstream bakend{#定义负载均衡设备的Ip及设备状态}{ # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #} #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 #虚拟主机的配置 server { #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.jd.com jd.com; index index.html index.htm index.php; root /data/www/jd; #对******进行负载均衡 # ~ 波浪线表示执行一个正则匹配，区分大小写 # ~* 表示执行一个正则匹配，不区分大小写 # ^~ 表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录 # = 进行普通字符精确匹配 location ~ .*.(php|php5)?$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10d; } #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ { expires 1h; } #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 \"/\" 启用反向代理 location / { proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; } #设定查看Nginx状态的地址 location /NginxStatus { stub_status on; access_log on; auth_basic \"NginxStatus\"; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 } #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; } #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ { expires 15d; } location ~ .*.(js|css)?$ { expires 1h; } }}######Nginx配置文件nginx.conf中文详解#####","link":"/2017/12/15/server/Nginx配置文件详解/"},{"title":"SSL-https配置","text":"主流证书格式介绍一般来说，主流的Web服务软件，通常都基于两种基础密码库：OpenSSL和Java。 Tomcat、Weblogic、JBoss等，使用Java提供的密码库。通过Java的Keytool工具，生成Java Keystore（JKS）格式的证书文件。 Apache、Nginx等，使用OpenSSL提供的密码库，生成PEM、KEY、CRT等格式的证书文件。 BM的产品，如Websphere、IBM Http Server（IHS）等，使用IBM产品自带的iKeyman工具，生成KDB格式的证书文件。 微软Windows Server中的Internet Information Services（IIS），使用Windows自带的证书库生成PFX格式的证书文件。如果您在工作中遇到带有后缀扩展名的证书文件，可以简单用如下方法区分： .DER .CER : 这样的证书文件是二进制格式，只含有证书信息，不包含私钥。 .CRT : 这样的文件可以是二进制格式，也可以是文本格式，一般均为文本格式，功能与.DER/*.CER相同。 .PEM : 一般是文本格式，可以放证书或私钥，或者两者都包含。 .PEM如果只包含私钥，那一般用 *.KEY代替。 .PFX .P12 是二进制格式，同时含证书和私钥，一般有密码保护。 怎么判断是文本格式还是二进制？ 用记事本打开，如果是规则的数字字母，如—–BEGIN CERTIFICATE—–MIIE5zCCA8+gAwIBAgIQN+whYc2BgzAogau0dc3PtzANBgkqh……—–END CERTIFICATE—–就是文本的，上面的BEGIN CERTIFICATE，说明这是一个证书如果是—–BEGIN RSA PRIVATE KEY—–，说明这是一个私钥 这些证书格式之间是可以互相转换的以下提供了一些证书之间的转换方法： 将JKS转换成PFX 可以使用Keytool工具，将JKS格式转换为PFX格式。 keytool -importkeystore -srckeystore D:\\server.jks -destkeystore D:\\server.pfx -srcstoretype JKS -deststoretype PKCS12 将PFX转换为JKS 可以使用Keytool工具，将PFX格式转换为JKS格式。 keytool -importkeystore -srckeystore D:\\server.pfx -destkeystore D:\\server.jks -srcstoretype PKCS12 -deststoretype JKS 将PEM/KEY/CRT转换为PFX 使用OpenSSL工具，可以将密钥文件KEY和公钥文件CRT转化为PFX文件。 将密钥文件KEY和公钥文件CRT放到OpenSSL目录下，打开OpenSSL执行以下命令： openssl pkcs12 -export -out server.pfx -inkey server.key -in server.crt 将PFX转换为PEM/KEY/CRT 使用OpenSSL工具，可以将PFX文件转化为密钥文件KEY和公钥文件CRT。 将PFX文件放到OpenSSL目录下，打开OpenSSL执行以下命令： openssl pkcs12 -in server.pfx -nodes -out server.pem openssl rsa -in server.pem -out server.key openssl x509 -in server.pem -out server.crt 请注意 此步骤是专用于使用keytool生成私钥和CSR申请证书，并且获取到pem格式证书公钥的情况下做分离私钥使用的，所以在实际部署证书时请使用此步骤分离出来的私钥和申请下来的公钥证书做匹配使用。 云盾证书服务统一使用 PEM 格式的数字证书文件。 pem证书转为jks证书第一步：pem(需要私钥) 转为 .pfx1openssl pkcs12 -export -out server.pfx -inkey private.key -in server.pem 第二步：.pfx 转为 .jks1keytool -importkeystore -srckeystore server.pfx -destkeystore server.jks -srcstoretype PKCS12 -deststoretype JKS tomcat配置1234567&lt;Connector protocol=\"org.apache.coyote.http11.Http11NioProtocol\" port=\"443\" SSLEnabled=\"true\" maxThreads=\"150\" scheme=\"https\" secure=\"true\" keystoreFile=\"/home/websoft/key/server.jks\" keystorePass=\"123456\" clientAuth=\"false\" sslProtocol=\"TLS\" ciphers=\"TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_RSA_WITH_AES_256_CBC_SHA256\" /&gt; ngnix配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647server { listen 80; listen 443 ssl; # ssl on; #在同一个server{}里配置同时开启http和https时，不需要开启此项！ server_name dev.cmop.mgtv.com; root /home/websoft/nginx/html; ssl_certificate \"/home/websoft/key/dev/full_chain.pem\"; ssl_certificate_key \"/home/websoft/key/dev/private.key\"; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1;#指定密码为openssl支持的格式 ssl_ciphers HIGH:!aNULL:!MD5;#密码加密方式 ssl_prefer_server_ciphers on; location / { } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { }}server { listen 80; listen 443 ssl; # ssl on; #在同一个server{}里配置同时开启http和https时，不需要开启此项！ server_name book.cmop.mgtv.com; root /home/websoft/nginx/html; ssl_certificate \"/home/websoft/key/book/full_chain.pem\"; ssl_certificate_key \"/home/websoft/key/book/private.key\"; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1;#指定密码为openssl支持的格式 ssl_ciphers HIGH:!aNULL:!MD5;#密码加密方式 ssl_prefer_server_ciphers on; location / { } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { }}","link":"/2018/01/08/server/SSL-https配置/"},{"title":"Linux查看物理CPU个数、核数、逻辑CPU个数","text":"CPU总核数 = 物理CPU个数 每颗物理CPU的核数总逻辑CPU数 = 物理CPU个数 每颗物理CPU的核数 * 超线程数 查看CPU信息（型号）1234567891011121314[root@AAA ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 24 Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz# 查看物理CPU个数[root@AAA ~]# cat /proc/cpuinfo| grep \"physical id\"| sort| uniq| wc -l2# 查看每个物理CPU中core的个数(即核数)[root@AAA ~]# cat /proc/cpuinfo| grep \"cpu cores\"| uniqcpu cores : 6# 查看逻辑CPU的个数[root@AAA ~]# cat /proc/cpuinfo| grep \"processor\"| wc -l24","link":"/2018/02/07/Linux/Linux查看物理CPU个数、核数、逻辑CPU个数/"},{"title":"Hexo博客（一）在GitHub搭建博客","text":"1 Git准备1.1 申请GitHub1、进入https://github.com/ 2、点击”New repository”，新建一个仓库。 注意：输入Repository name:yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了) 3、启用GitHub Page 点击右边的“Setting”菜单进入设置,点击”Launch automatic page generator”，然后再点击点击底部的”Continue to layouts”。最后点击”Publish page”,发布github默认生成的一个静态站点。 4、验证邮箱 点击右上角个人设置的“Setting”菜单进入设置，再点击Emails,点击”Send verification Email”发送验证邮件。进入你的邮箱，查收验证邮件进行验证。 1.2 安装Git1.2.1下载https://git-for-windows.github.io/ 1.2.2安装 安装过程中，询问是否修改环境变量，选择“Use Git Bash Only”. 即只在msysGit提供的Shell (NOTE: 这个步骤最好选择第二项“Use Git from the Windows Command Prompt”， 这样在Windows的命令行cmd中也可以运行git命令了。这样会对以后的一些操作带来方便，比如Win7下安装配置gVim) 配置行结束标记，保持默认“Checkout Windows-style, commit Unix-style line endings”. 1.2.3中文乱码问题解决方法ls 不能显示中文目录 解决办法：在git/git-completion.bash中增加一行【4】： 1alias ls='ls --show-control-chars --color=auto' 另外，Git Shell 不支持 ls -l的缩写形式ll，也为其添加一个alias 1alias ll='ls -l' 1.2.4 运行 Git 前的配置 配置你个人的用户名称和电子邮件地址,打开git bash。 12$git config --global user.name \"xxx\"$git config --global user.email xxx@example.com 配置GitHub SSH （1）首先使用 ssh-keygen 生成 SSH 密钥123456cd ~/.ssh/Administrator@THINKPAD ~/.ssh ls known_hostsssh-keygen -t rsa -C \"youremail@example.com\" 有提示，直接回车即可。生成key以后检查下”~”目录下的.ssh目录下是否多了2个文件 。 把 id_rsa.pub 中的全部内容复制，包括最后的一个换行。或者用命令：1clip &lt; ~/.ssh/id_rsa.pub （2）配置Github SSH。 登陆GitHub-&gt;Settings-&gt;“SSH Keys”，然后，点“Add SSH Key”，起个Title，在Key文本框里粘贴id_rsa.pub文件的内容，点“Add Key”。 （3）测试是否可以连接到github1234ssh git@github.comHi imsofter! You've successfully authenticated, but GitHub does not provide shell access.Connection to github.com closed. 现在可以将代码推上github上了。 2 安装node.js下载：http://nodejs.org/download/ 可以下载 node-v4.2.1-x64.msi 安装时直接保持默认配置即可。 3 安装Hexo关于Hexo的安装配置过程，请以官方Hexo给出的步骤为准,大致如下： 在电脑上E盘新建一个blog文件夹,该文件夹用于存放你的博客文件,然后右键单击选择“Git Bash” 3.1 Installation打开Git命令行，执行如下命令1$ npm install hexo-cli g 3.2 Quick Start1. Setup your blog 在电脑中建立一个名字叫「Hexo」的文件夹（比如我建在了E:\\Hexo），然后在此文件夹中右键打开Git Bash。执行下面的命令12345$ cd /e/blog$ hexo init[info] Copying data[info] You are almost done! Don't forget to run `npm install` before you start blogging with Hexo! Hexo随后会自动在目标文件夹建立网站所需要的文件。 然后按照提示，运行 npm install（在 /e/blog下）1npm install 会在e:\\blog目录中生成 node_modules。 安装其它插件12345678npm install hexo-server --savenpm install hexo-admin --savenpm install hexo-generator-archive --savenpm install hexo-generator-feed --savenpm install hexo-generator-search --savenpm install hexo-generator-tag --savenpm install hexo-deployer-git --savenpm install hexo-generator-sitemap --save 2. Start the server 运行下面的命令（在 /E/Hexo下）12$ hexo server[info] Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 表明Hexo Server已经启动了，在浏览器中打开 http://localhost:4000/，这时可以看到Hexo已为你生成了一篇blog。 你可以按Ctrl+C 停止Server。 3. Create a new post 新打开一个git bash命令行窗口，cd到/e/blog下，执行下面的命令12$ hexo new \"My New Post\"[info] File created at e:\\blog\\source\\_posts\\My-New-Post.md 刷新http://localhost:4000/，可以发现已生成了一篇新文章 “My New Post”。 NOTE： 有一个问题，发现 “My New Post” 被发了2遍，在Hexo server所在的git bash窗口也能看到create了2次。1234$ hexo server[info] Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.[create] e:\\blog\\source\\_posts\\My-New-Post.md[create] e:\\blog\\source\\_posts\\My-New-Post.md 经验证，在hexo new “My New Post” 时，如果按Ctrl+C将hexo server停掉，就不会出现发2次的问题了。 所以，在hexo new文章时，需要stop server。 4. Generate static files 执行下面的命令，将markdown文件生成静态网页。 该命令执行完后，会在 E:\\blog\\public\\ 目录下生成一系列html，css等文件。 5. 编辑文章 hexo new “My New Post”会在E:\\blog\\source_posts目录下生成一个markdown文件：My-New-Post.md 可以使用一个支持markdown语法的编辑器（比如 Sublime Text 2）来编辑该文件。 6. 部署到Github 运行 npm install hexo-deployer-git --save 安装git支持 部署到Github前需要配置_config.yml文件，首先找到下面的内容1234# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: 然后将它们修改为123456# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: github repository: git@github.com:hmiter/hmiter.github.io.git branch: master NOTE1: Repository：必须是SSH形式的url（git@github.com:hmiter/hmiter.github.io.git），而不能是HTTPS形式的url（https://github.com/hmiter/hmiter.github.io.git），否则会出现错误：123$ hexo deploy[info] Start deploying: github[error] https://github.com/hmiter/hmiter.github.io is not a valid repositor URL! 使用SSH url，如果电脑没有开放SSH 端口，会致部署失败。12fatal: Could not read from remote repository.Please make sure you have the correct access rights and the repository exists. NOTE2： 如果你是为一个项目制作网站，那么需要把branch设置为gh-pages。 NOTE3： hexo3.0以上的版本type为git 7. 测试 当部署完成后，在浏览器中打开http://hmiter.github.io/（https://hmiter.github.io/） ，正常显示网页，表明部署成功。 8. 总结：部署步骤 每次部署的步骤，可按以下三步来进行。123hexo cleanhexo generatehexo deploy 9. 总结：本地调试 在执行下面的命令后，12$ hexo g #生成$ hexo s #启动本地服务，进行文章预览调试 浏览器输入http://localhost:4000，查看搭建效果。此后的每次变更_config.yml 文件或者新建文件都可以先用此命令调试，尤其是当你想调试新添加的主题时。 可以用简化的一条命令1hexo s -g 10.hexo命令缩写hexo支持命令缩写，如下所示。hexo g等价于hexo generate1234hexo g：hexo generatehexo c：hexo cleanhexo s：hexo serverhexo d：hexo deploy","link":"/2017/01/04/hexo/Hexo博客（一）在GitHub搭建博客/"},{"title":"Hexo博客（二）更换主题和相关设置","text":"更换主题icarus1、下载icarus主题地址：https://github.com/ppoffice/hexo-theme-icarus2、更换主题icarus，修改Hexo的_config.yml里面的theme如下：1theme: icarus 搜索插件主题已经集成了，主题的_config.yml1234search: insight: true # you need to install `hexo-generator-json-content` before using Insight Search swiftype: # enter swiftype install key here baidu: false # you need to disable other search engines to use Baidu search, options: true, false 默认配置不用改。但是需要安装hexo-generator-json-content。命令如下：1$ npm install -S hexo-generator-json-content 打赏在国外比较流行打赏，在中国嘛…有总比没有好，万一有人打赏呢？是吧。在主题配置文件_config.yml的comment上面添加:123#donate 打赏donate: true # options: true , falsedonate_message: 如果您觉得文章不错,可以请我喝一杯咖啡！ 在layout添加文件jdonate.ejs，内容如下：123456789101112131415161718192021222324252627&lt;! -- 添加捐赠图标 --&gt;&lt;div class =\"post-donate\"&gt; &lt;div id=\"donate_board\" class=\"donate_bar center\"&gt; &lt;a id=\"btn_donate\" class=\"btn_donate\" href=\"javascript:;\" title=\"打赏\"&gt;&lt;/a&gt; &lt;span class=\"donate_txt\"&gt; &lt;%=theme.donate_message%&gt; &lt;/span&gt; &lt;br&gt; &lt;/div&gt; &lt;div id=\"donate_guide\" class=\"donate_bar center hidden\" &gt; &lt;!-- 支付宝打赏图案 --&gt; &lt;img src=\"/img/zhifubao.png\" alt=\"支付宝打赏\" &gt; &lt;!-- 微信打赏图案 --&gt; &lt;img src=\"/img/weixin.png\" alt=\"微信打赏\" &gt; &lt;/div&gt; &lt;script type=\"text/javascript\"&gt; document.getElementById('btn_donate').onclick = function(){ if($('#donate_guide').hasClass('hidden')){ $('#donate_guide').removeClass('hidden'); }else{ $('#donate_guide').addClass('hidden'); } } &lt;/script&gt;&lt;/div&gt;&lt;! -- 添加捐赠图标 --&gt; 在主题source\\css_partial目录新增donate.styl：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647.donate_bar { text-align: center; background: #fff --margin-top: 5%}.donate_bar a.btn_donate { display: inline-block; width: 82px; height: 82px; margin-left: auto; margin-right: auto; background: url(../img/btn_reward.gif)no-repeat; -webkit-transition: background 0s; -moz-transition: background 0s; -o-transition: background 0s; -ms-transition: background 0s; transition: background 0s}.donate_bar a.btn_donate:hover { background-position: 0 -82px}.donate_bar .donate_txt { display: block; color: #9d9d9d; font: 14px/2 \"Microsoft Yahei\"}.donate_bar.hidden{ display: none}.post-donate{ --margin-top: 80px;}#donate_guide{ height: 320px; width: 100%; margin: 0 auto;}#donate_guide img{ height: 300px; height: 300px;} btn_reward.gif直接拿我的，然后放在img目录吧。最后修改layout\\common\\article.ejs，添加如下：1234567&lt;footer class=\"article-footer\"&gt; &lt;% if (!index &amp;&amp; theme.donate){ %&gt; &lt;%- partial('donate') %&gt; &lt;% } %&gt; &lt;%- partial('share/index', { post: post }) %&gt; &lt;%- partial('comment/counter', { post: post }) %&gt;&lt;/footer&gt; 需要在加入icarus/css/style.styl计入@import ‘_partial/donate’ 添加评论这个主题的评论已经集成了，并不需要我们进行手工导入，要求你有多说或者disqus的账号。1234comment: disqus: # enter disqus shortname here duoshuo: # enter duoshuo shortname here youyan: # enter youyan uid here disqus是国外的，不适用。我们选择duoshuo。在多说注册账号：http://duoshuo.com/创建站点后在主题目录的_config.yml中填写shortname： duoshuo: 多说设置的名称 分享主题已经集成，只需要配置即可。启用jiathis，如下12# Share 分享share: jiathis # options: jiathis, bdshare, addtoany, default 百度/谷歌验证站点为什么要验证站点了，因为要搜索引擎进行收录，说白了就是让别人更容易搜索到你的网站，仅此而已。首先需要到百度/谷歌站长统计中注册，以及验证：百度站长工具Google网站管理员工具地址注册完后，进行输入相应的网站地址，然后选择html验证，将代码加入以下路径layout/_partial/head.ejs：12345&lt;head&gt; &lt;meta name=\"baidu-site-verification\" content=\"xxxx\" /&gt; &lt;meta name=\"google-site-verification\" content=\"xxxx\" /&gt; &lt;meta charset=\"utf-8\"&gt; .... 然后发布到github中，再进行验证即可。 添加站长统计我们通过站长统计来及时查看我们个人网站的浏览情况。我寻找cnzz，需要先注册：站长统计1、在theme的_config.yml中的末尾添加以下：12# CNZZ web_idcnzz: CNZZ的web_id 2、在主题目录的layout/common添加文件为cnzz.ejs，内容如下：123&lt;% if (theme.cnzz){ %&gt;Analyse with &lt;script src=\"http://s23.cnzz.com/z_stat.php?id=&lt;%= theme.cnzz %&gt;&amp;web_id=&lt;%= theme.cnzz %&gt;\" language=\"JavaScript\"&gt;&lt;/script&gt;&lt;% } %&gt; 如需其他形式的，请参数CNZZ上的代码。3、最后进行显示，在路径layout/common/footer.ejs里面添加1...PPOffice&lt;/a&gt;.&lt;%- partial('cnzz') %&gt; 提醒：注意在_config.xml中添加web_id， 自定义widget在layout/widget 自定义模板即可，例如：1234567891011121314151617&lt;% if (site.tags.length) { %&gt;&lt;div class=\"card widget\"&gt; &lt;div class=\"card-content\"&gt; &lt;h3 class=\"menu-label\"&gt; &lt;%= __('widget.announcement') %&gt; &lt;/h3&gt; &lt;p class=\"board\"&gt; 欢迎来访问！&lt;br&gt; QQ：150045153&lt;br&gt; 微信：150045153&lt;br&gt; 邮箱：hmiter@sina.com&lt;br&gt;&lt;br&gt; 欢迎交流与分享经验! &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;% } %&gt; categories和tags页面不显示解决办法默认是没有 categories 和 tags 的需要12hexo new page \"tags\" hexo new page \"categories\" 编辑 /tags/index.md /categories/index.md12345type: \"tags\"layout: \"tags\"type: \"categories\"layout: \"categories\"","link":"/2017/02/06/hexo/Hexo博客（二）更换主题和相关设置/"}],"tags":[{"name":"Android","slug":"android","link":"/tags/android/"},{"name":"Hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"Server","slug":"Server","link":"/tags/Server/"},{"name":"Database","slug":"database","link":"/tags/database/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"}],"categories":[{"name":"programming","slug":"programming","link":"/categories/programming/"},{"name":"Hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"javase源码分析","slug":"javase源码分析","link":"/categories/javase源码分析/"}]}